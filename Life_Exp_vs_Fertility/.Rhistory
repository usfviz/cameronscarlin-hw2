win_lose_stay <- MontyHall(10000, "stay")
blah = c(1,2)
blah + win_lose_stay
win_lose_stay <- c(0.0,0.0)
win_lose_switch <- c(0.0,0.0)
for (i in 10000){
win_lose_stay <- win_lose_stay + MontyHall(1000, "stay")
win_lose_switch <- win_lose_switch + MontyHall(1000, "switch")
}
print(win_lose_switch/10000)
print(win_lose_stay/10000)
win_lose_stay <- c(0.0,0.0)
win_lose_switch <- c(0.0,0.0)
for (i in 1:1000){
win_lose_stay <- win_lose_stay + MontyHall(1000, "stay")
win_lose_switch <- win_lose_switch + MontyHall(1000, "switch")
}
MontyHall <- function(NumSamples, SwitchOrStay){
DoorWithCar <- as.integer(runif(NumSamples,1,4))
FirstGuess <- as.integer(runif(NumSamples,1,4))
FirstGuessCar <- 0.0
FirstGuessGoat <- 0.0
TimesWonCar <- 0.0
TimesWonGoat <- 0.0
doors <- c(1,2,3)
for (i in 1:NumSamples){
DoorsWithGoats <- doors[-DoorWithCar[i]]
if (FirstGuess[i] %in% DoorsWithGoats){
FirstGuessGoat <-  FirstGuessGoat + 1
DoorToShow <- DoorsWithGoats[DoorsWithGoats != FirstGuess[i]]
if (SwitchOrStay == 'switch'){
FinalGuess <- DoorWithCar[i] #car, if first guess is goat and switch, then car
} else{
FinalGuess <- FirstGuess[i] #goat, if first guess is goat and stay, then goat
}
} else{
FirstGuessCar <- FirstGuessCar + 1
if (SwitchOrStay == 'switch'){
FinalGuess <- 'goat'    #goat, if first guess car and switch, then goat
} else {
FinalGuess <- FirstGuess[i] #car, if first guess car and stay, then car
}
}
if (FinalGuess == DoorWithCar[i]){
TimesWonCar = TimesWonCar + 1
} else{
TimesWonGoat <- TimesWonGoat + 1
}
}
Win_Lose <- c(TimesWonCar/NumSamples, TimesWonGoat/NumSamples)
#print(paste("Odds of winning car when we", SwitchOrStay, '=',TimesWonCar/NumSamples))
#print(paste("Odds of winning goat when we", SwitchOrStay, '=',TimesWonGoat/NumSamples))
return(Win_Lose)
}
win_lose_stay <- c(0.0,0.0)
win_lose_switch <- c(0.0,0.0)
for (i in 1:1000){
win_lose_stay <- win_lose_stay + MontyHall(1000, "stay")
win_lose_switch <- win_lose_switch + MontyHall(1000, "switch")
}
print(win_lose_switch/10000)
print(win_lose_stay/10000)
print(win_lose_switch/1000)
print(win_lose_stay/1000)
plot(win_lose_switch)
hist(win_lose_switch)
hist(x=win_lose_switch)
hist(win_lose_switch, freq=NULL)
barplot(win_lose_switch)
barplot(density =win_lose_switch)
barplot(height =win_lose_switch)
barplot(height =win_lose_switch, Main = "1000 Monty Hall Sims (1,000 samples each)")
barplot(height =win_lose_switch, title = "1000 Monty Hall Sims (1,000 samples each)")
barplot(height =win_lose_switch, main = "1000 Monty Hall Sims (1,000 samples each)")
barplot(height =win_lose_switch, main = "1000 'Switch' Monty Hall Sims (1,000 samples each)")
barplot(height =win_lose_switch,
main = "1,000 'Switch' Monty Hall Sims (1,000 samples each)",
xlab = 'Was the car won?',
names.arg= c('Yes','No'))
barplot(height =win_lose_switch,
main = "1,000 'Switch' Monty Hall Sims (1,000 samples each)",
xlab = 'Was the car won?',
ylab = 'Average over 1,000 sims'
names.arg= c('Yes','No'))
barplot(height =win_lose_switch,
main = "1,000 'Switch' Monty Hall Sims (1,000 samples each)",
xlab = 'Was the car won?',
ylab = 'Average over 1,000 sims',
names.arg= c('Yes','No'))
barplot(height =win_lose_stay,
main = "1,000 'Stay' Monty Hall Sims (1,000 samples each)",
xlab = 'Was the car won?',
ylab = 'Average over 1,000 sims',
names.arg= c('Yes','No'))
DaysOfYear <- c(1:365)
set(2,3,4,5,5,5,)
duplicated(c(2,3,4,5,5))
TRUE %in% duplicated(c(2,3,4,5,5))
TRUE %in% duplicated(c(2,3,4,5))
BDays <- sample(DaysOfYear, n, replace=T)
n <- 30
BDays <- sample(DaysOfYear, n, replace=T)
TRUE %in% duplicated(BDays)
BDays
duplicated(BDays)
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
DuplicateBDays <- 0
NoDuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(DuplicateBDays/10000)
for (n in 2:20){
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(paste(n,"people with at least 2 with common bdays has a probability of "DuplicateBDays/10000)
}
for (n in 2:20){
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(paste(n,"people with at least 2 with common bdays has a probability of",DuplicateBDays/10000)
}
for (n in 2:20){
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(paste(n,"people with at least 2 with common bdays has a probability of",DuplicateBDays/10000))
}
for (n in 2:20){
DuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(paste(n,"people with at least 2 with common bdays has a probability of",DuplicateBDays/10000))
}
for (n in 2:30){
DuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(paste(n,"people with at least 2 with common bdays has a probability of",DuplicateBDays/10000))
}
for (n in 2:25){
DuplicateBDays <- 0
for (i in 1:10000){
BDays <- sample(DaysOfYear, n, replace=T)
if (TRUE %in% duplicated(BDays)){
DuplicateBDays <- DuplicateBDays + 1
}
}
print(paste(n,"people with at least 2 with common bdays has a probability of",DuplicateBDays/10000))
}
TwoB <- function(N){
X <- (1/N)*(1/100)*(99/100)**(N-1)
}
print(TwoB(5))
for i in range(203:1000){
val <- val + TwoB(i)
}
print(val)
val <- 0
for i in range(203,1000){
val <- val + TwoB(i)
}
print(val)
for (i in c(203:1000)){
val <- val + TwoB(i)
}
print(val)
c(203:1000)
for (i in c(203:10000)){
val <- val + TwoB(i)
print i
}
print(val)
for (i in c(203:10000)){
val <- val + TwoB(i)
print(i)
}
for (i in c(203:10000)){
val <- val + TwoB(i)
}
print(val)
for (i in c(203:100000)){
val <- val + TwoB(i)
}
print(val)
val <- 0
for (i in c(203:1000000)){
val <- val + TwoB(i)
}
print(val)
1/val
(.99**202)/.01
(2125.361/100)*(.99**202)/.01
TwoBVar <- function(N){
2125.36*(1/100)*(1/N)*(99/100)**(N-1)*(N-279.09)**2
}
var2b <- 0
for (i in c(203:100000)){
var2b <- var2b + TwoBVar(i)
}
print(sqrt(var2b))
var2b <- 0
for (i in c(203:100000)){
var2b <- var2b + TwoBVar(i)
}
print(var2b)
shiny::runApp('MSAN/MSAN-DataViz/lab2/class-code/intro-shiny/interactive-app-2')
install.packages(c("cluster", "curl", "DBI", "directlabels", "expm", "ks", "lattice", "mvtnorm", "openxlsx", "pbkrtest", "psych", "RcppEigen", "readr", "rgl", "rmarkdown", "scatterplot3d", "shiny", "sourcetools", "SparseM", "stringi", "survival", "tibble", "viridis"))
[1,2,3]
r_gamma_1a <- rgamma(10000,238,scale=1/10)
mean(r_gamma_1a) # pretty close to sample mean
fatal <- read.csv('fatal.csv')
sample_mean_1a <- mean(fatal$fatal_accidents)
r_gamma_1a <- rgamma(10000,238,rate=10)
mean(r_gamma_1a) # pretty close to sample mean
r_poiss_1a <- rpois(10000,r_gamma_1a)
r_poiss_1a <- sort(r_poiss_1a)
r_poiss_1a[250]
r_poiss_1a[9751]
miles <- (fatal$passenger_deaths/fatal$death_rate)
miles <- (fatal$passenger_deaths/fatal$death_rate)*100000000
miles <- (fatal$fatal_accidents/fatal$death_rate)*100000000
miles
miles <- (fatal$passenger_deaths/fatal$death_rate)*100000000
xbar <- mean(miles)
xbar
r_gamma_1b <- rgamma(10000, 238, rate = 10*xbar)
r_poiss_1b <- rpois(10000, r_gamma_1b*8*10^12)
r_poiss_1b <- rpois(10000, r_gamma_1b*8*10^11)
r_poiss_1b <- sort(r_poiss_1b)
r_poiss_1b[250]
r_poiss_1b[9750]
mean_deaths <- mean(fatal$passenger_deaths)
r_gamma_1c <- rgamma(10000,6919,rate=10)
r_poiss_1c <- rpois(10000,r_gamma_1c)
r_poiss_1c <- sort(r_poiss_1c)
r_poiss_1c[250]
r r_poiss_1c[9751]
r_poiss_1c[9751]
r_gamma_1d <- rgamma(10000, 6919, rate = 10*xbar)
r_poiss_1d <- rpois(10000, r_gamma_1d*8*10^11)
r_poiss_1d <- sort(r_poiss_1d)
training <- read.csv('OnlineNewsPopularityTraining.csv')
setwd("~/MSAN/MSAN-CompStats/HW4")
training <- read.csv('OnlineNewsPopularityTraining.csv')
test <- read.csv('OnlineNewsPopularityTest.csv')
View(training)
training <- training[-c('url','shares','timedelta')]
training <- training[,-c('url','shares','timedelta')]
training <- training[,!(names(training) %in% -c('url','shares','timedelta'))]
training <- training[,!(names(training) %in% c('url','shares','timedelta'))]
test <- test[,!(names(test) %in% c('url','shares','timedelta'))]
training <- na.omit(training)
training <- read.csv('OnlineNewsPopularityTraining.csv')
training <- training[,!(names(training) %in% c('url','shares','timedelta'))]
training <- na.omit(training)
library(glmnet, quietly = TRUE)
library(ISLR, quietly = TRUE)
install.packages("glmnet", repos='http://cran.us.r-project.org')
train_x <- model.matrix(popular ~., data = training)[, -1]
train_x
train_y <- training$popular
attach(Hitters)
?Hitters
names(Hitters)
sum(is.na(Hitters))
Hitters <- na.omit(Hitters)
x <- model.matrix(Salary ~., data = Hitters)[, -1]
y <- Hitters$Salary
grid.lambda <- 10^seq(10, -2, length = 100)
grid.lambda
ridge.model <- glmnet(x, y, alpha = 0, lambda = grid.lambda)
library(glmnet, quietly = TRUE)
library(ISLR, quietly = TRUE)
ridge.model <- glmnet(x, y, alpha = 0, lambda = grid.lambda)
plot(ridge.model)
ridge.model$lambda[50]
coef(ridge.model)[, 50]
sqrt(sum(coef(ridge.model)[-1, 50]^2))
ell2.norm <- numeric()
for(i in 1:length(grid.lambda)){
ell2.norm[i] <- sqrt(sum(coef(ridge.model)[-1, i]^2))
}
plot(x = grid.lambda, y = ell2.norm, xlab = expression(lambda), ylab = "L2 Norm", xlim = c(10,10000))
set.seed(1) #for reproducability
train <- sample(1:nrow(x), nrow(x) / 2)
test <- (-train)
y.train <- y[train]
y.test <- y[test]
ridge.model.train <- glmnet(x[train, ], y.train, alpha = 0, lambda = grid.lambda)
set.seed(1) #for reproducability
cv.out <- cv.glmnet(x[train, ], y.train, alpha = 0)
plot(cv.out)
plot(cv.out)
best.lambda <- cv.out$lambda.min
best.lambda
plot(cv.out)
abline(v = log(best.lambda), col = "blue", lwd = 2)
abline(v = log(best.lambda), col = "blue", lwd = 2)
plot(cv.out)
ridge.pred <- predict(ridge.model.train, s = best.lambda, newx = x[test, ])
mspe.ridge <- mean((ridge.pred - y.test)^2)
mspe.ridge
final.model <- glmnet(x, y, alpha = 0, lambda = best.lambda)
Coef.Ridge <- coef(final.model)[1:20, ]
Coef.Ridge
shiny::runApp('~/MSAN/MSAN-DataViz/HW2/Life_Exp_vs_Fertility')
setwd("~/MSAN/MSAN-DataViz")
setwd("~/MSAN/MSAN-DataViz/HW2/Life_Exp_vs_Fertility")
runApp()
runApp()
runApp()
attach(Smarket)
plot(Volume)
pairs(Smarket[, -6], col = Smarket$Direction)
library(glmnet, quietly = TRUE)
library(ISLR, quietly = TRUE)
training <- read.csv('OnlineNewsPopularityTraining.csv')
test <- read.csv('OnlineNewsPopularityTest.csv')
training <- training[,!(names(training) %in% c('url','shares','timedelta'))]
test <- test[,!(names(test) %in% c('url','shares','timedelta'))]
View(training)
Smarket
pairs(Smarket[, -6], col = Smarket$Direction)
pairs(Smarket[, 1:5], col = Smarket$Direction)
pairs(training[,1:8], col=training$popular)
runif(0,1,100)
runif(100,0,1)
training_subset <- training[runif(31716,0,1) < 0.1]
training_subset <- training[runif(31716,0,1) < 0.1,]
set.seed(1)
training_subset <- training[runif(31716,0,1) < 0.1,]
set.seed(1)
training_subset <- training[runif(31716,0,1) < 0.1,]
View(training_subset)
pairs(training_subset[,1:8], col=training_subset$popular)
pairs(training_subset[,1:8], col=as.factor(training_subset$popular))
install.packages("pairsD3")
shiny::runGitHub('garthtarr/pairsD3-shiny')
set.seed(1)
training_subset <- training[runif(31716,0,1) < 0.05,]
pairs(training_subset[,1:8], col=as.factor(training_subset$popular))
pairs(training_subset[,1:10], col=as.factor(training_subset$popular))
pairs(training_subset[,1:6], col=as.factor(training_subset$popular))
summary(logreg_allfeatures)
logreg_allfeatures <- glm(popular~., data=training_subset, family=binomial)
summary(logreg_allfeatures)
logreg_allfeatures <- glm(popular~., data=training, family=binomial)
summary(logreg_allfeatures)
glm.probs <- predict(logreg_allfeatures, test, type = "response")
glm.probs <- predict(logreg_allfeatures, test)
glm.probs <- predict(logreg_allfeatures, test, type = "response")
test_predict <- predict(logreg_allfeatures, test, type = "response")
test_predict[test_predict>.5]
test_predict[test_predict>.5] <- 1
test_predict[test_predict<.5] <- 0
table(test_predict,test$popular)
mean(test_predict==test$popular)
table(test$popular)
logreg_allfeatures$coefficients
logreg_allfeatures$coefficients > 0.5
logreg_allfeatures$coefficients[logreg_allfeatures$coefficients > 0.5]
logreg_allfeatures$coefficients > 0.5
logreg_allfeatures$coefficients
logreg_allfeatures$residuals
logreg_allfeatures$effects
logreg_allfeatures$model
logreg_allfeatures$
logreg_allfeatures$coefficients[logreg_allfeatures$coefficients < 0.5]
logreg_allfeatures$effects
logreg_allfeatures <- glm(popular~., data=training, family=binomial)
logreg_allfeatures <- glm(popular~., data=training, family=binomial)
summary(logreg_allfeatures)
logreg_50p <- glm(popular~.-n_unique_tokens-n_non_stop_words-n_non_stop_unique_tokens-kw_min_max-self_reference_max_shares-weekday_is_sunday-is_weekend-LDA_00-LDA_01-LDA_02-LDA_03-LDA_04-global_sentiment_polarity-global_rate_negative_words-rate_positive_words-rate_negative_words-max_positive_polarity-abs_title_sentiment_polarity, data=training, family=binomial)
summary(logreg_50p)
test_predict_50 <- predict(logreg_50p, test, type = "response")
test_predict_50[test_predict_50>.5] <- 1
test_predict_50[test_predict_50<.5] <- 0
table(test_predict_50,test$popular)
table(test$popular)
mean(test_predict_50==test$popular)
table(test_predict_50,test$popular)
table(test$popular)
table(test_predict,test$popular)
mean(test_predict_50==test$popular)
table(test_predict_50,test$popular)
test_predict_50 <- predict(logreg_50p, test, type = "response")
test_predict_50[test_predict_50>.5] <- 1
test_predict_50[test_predict_50<.5] <- 0
table(test_predict_50,test$popular)
table(test$popular)
mean(test_predict_50==test$popular) # Much smaller amount of variables, but nearly the same accuracy
mean(test_predict==test$popular) # 79% accuracy, but barely got any positive cases
table(test$popular)
install.packages(plotly)
install.packages('plotly')
library(plotly)
runApp()
runApp()
runApp()
